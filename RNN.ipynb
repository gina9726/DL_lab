{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically reload changes to external code\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from mnist import loader #loader for mnist dataset\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.python.ops import rnn\n",
    "import numpy as np\n",
    "import pdb, time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mnist dataset\n",
    "\n",
    "The MNIST database of handwritten digits. [[website]](http://yann.lecun.com/exdb/mnist/)<br>\n",
    "There are **60,000** training images and **10,000** testing images in this dataset.<br>\n",
    "Each digit is a one-channel image. Size of image = 28*28 = 784.\n",
    "\n",
    "![](imgs/mnist_ex.png)\n",
    "\n",
    "There are some build-in mnist function can be used in tensorflow.\n",
    "\n",
    "Ex.<br>\n",
    "from tensorflow.examples.tutorials.mnist import input_data<br>\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "\n",
    "Instead of using these functions, I'll use the orginal dataset manually in this code.<br>\n",
    "It's more clear to trace the data-processing.\n",
    "\n",
    "When we load the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load mnist data manually\n",
    "# loading 'train' or 'test' data\n",
    "# ex. load_mnist_data('train')\n",
    "# return images, labels and mean of all images. (But, we'll only use the mean of training data.)\n",
    "# ims: [N * 784]\n",
    "# labels: [N]\n",
    "# ims_mean: [784]\n",
    "\n",
    "def load_mnist_data(flag, data_path='data'):\n",
    "    data_loader = loader.MNIST(data_path)\n",
    "    if flag == 'train':\n",
    "        ims, labels = data_loader.load_training()\n",
    "    elif flag == 'test':\n",
    "        ims, labels = data_loader.load_testing()\n",
    "    else:\n",
    "        raise ValueError(\"Error. Only training or testing data.\")\n",
    "    ims = ims/255.0\n",
    "    ims_mean = np.mean(ims, axis=0)\n",
    "    ims = np.reshape(ims, [len(ims),28,28])\n",
    "    ims_mean = np.reshape(ims_mean,(28,28))\n",
    "    return ims, labels, ims_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 1\n",
    "batch_size = 100   # training batch size\n",
    "test_batch_size = 100\n",
    "display_step = 50  # testing \n",
    "\n",
    "# Network Parameters\n",
    "n_input = 28 # MNIST data input (img shape: 28*28)\n",
    "n_steps = 28 # timesteps\n",
    "n_hidden = 128 # hidden layer num of features\n",
    "n_classes = 10 # MNIST total classes (0-9 digits)\n",
    "stddev=0.01    # standard deviation for random initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions of Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RNN():\n",
    "    rnn_cell = tf.nn.rnn_cell\n",
    "    # tf Graph input\n",
    "    x = tf.placeholder(\"float\", [None, n_steps, n_input])  # mnist input images, [batch_size x 28 x 28]\n",
    "    y = tf.placeholder(tf.int32,[None])              # label, [batch_size]\n",
    "    # Declare Variables \n",
    "    # Store layers weight & bias\n",
    "    weights = {\n",
    "        'out': tf.Variable(tf.random_normal([n_hidden, n_classes]))\n",
    "    }\n",
    "    biases = {\n",
    "        'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "    }\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = rnn_cell.BasicLSTMCell(n_hidden, forget_bias=1.0)\n",
    "    # Initial zero state\n",
    "    state = lstm_cell.zero_state(batch_size, tf.float32)\n",
    "    for i in range(n_steps):\n",
    "        # Get lstm cell output\n",
    "        with tf.variable_scope('lstm', reuse=True if i > 0 else None):\n",
    "            output, state = lstm_cell(x[:,i,:], state)\n",
    "    \n",
    "    pred = tf.matmul(output, weights['out']) + biases['out']\n",
    "\n",
    "    probs = tf.nn.softmax(pred)\n",
    "    log_probs = tf.log(probs + 1e-8)\n",
    "\n",
    "    one_hot_y = tf.one_hot(y, n_classes, on_value=1, off_value=0, axis=-1)\n",
    "    #print one_hot_y.get_shape()\n",
    "    #cross_entropy_loss = - tf.mul(y,log_probs)\n",
    "    cross_entropy_loss = - tf.multiply(tf.cast(one_hot_y, tf.float32),log_probs)\n",
    "    \n",
    "    loss = tf.reduce_sum(cross_entropy_loss)\n",
    "    \n",
    "\n",
    "\n",
    "    return x, y, loss, pred, one_hot_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_model(sess, x, y, ims, labels, ims_test, labels_test, ims_mean, iter_per_epoch, test_iter):\n",
    "    Train_Loss = 0\n",
    "    Test_Loss = 0\n",
    "    Train_Acc = 0\n",
    "    Test_Acc = 0\n",
    "    for idx in xrange(iter_per_epoch):\n",
    "        batch_xs = ims[order_list[idx*batch_size:(idx+1)*batch_size]] - ims_mean\n",
    "        batch_ys = labels[order_list[idx*batch_size:(idx+1)*batch_size]]\n",
    "        C, A = sess.run([cost, accuracy], feed_dict={x: batch_xs, y: batch_ys})\n",
    "        Train_Loss += C/batch_size   # calculate the loss in average (per image).\n",
    "        Train_Acc += A\n",
    "    # Eval testing dataset\n",
    "    for idx in xrange(test_iter):\n",
    "        batch_xs = ims_test[order_list[idx*test_batch_size:(idx+1)*test_batch_size]] - ims_mean\n",
    "        batch_ys = labels_test[order_list[idx*test_batch_size:(idx+1)*test_batch_size]]\n",
    "        C, A = sess.run([cost, accuracy], feed_dict={x: batch_xs, y: batch_ys})\n",
    "        Test_Loss += C/test_batch_size\n",
    "        Test_Acc += A\n",
    "    return Train_Loss, Train_Acc, Test_Loss, Test_Acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main function\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/planck/anaconda2/lib/python2.7/site-packages/tensorflow/python/util/tf_should_use.py:170: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "------After Random Initialization------\n",
      "Training: loss=2.548789, acc=0.157283.\t\tTesting: loss=2.536077, acc=0.162200\n",
      " 6.732644 seconds\n",
      "------Start Training------\n",
      "Epoch 0.000000, Training: loss=2.276403, acc=0.294050.\t\tTesting: loss=2.274047, acc=0.297300\n",
      "Epoch 0.083333, Training: loss=0.542239, acc=0.828167.\t\tTesting: loss=0.527062, acc=0.836800\n",
      "Epoch 0.166667, Training: loss=0.339373, acc=0.894167.\t\tTesting: loss=0.338311, acc=0.893000\n",
      "Epoch 0.250000, Training: loss=0.254496, acc=0.922950.\t\tTesting: loss=0.247378, acc=0.924100\n",
      "Epoch 0.333333, Training: loss=0.200234, acc=0.937950.\t\tTesting: loss=0.186873, acc=0.940900\n",
      "Epoch 0.416667, Training: loss=0.154682, acc=0.952333.\t\tTesting: loss=0.154590, acc=0.950500\n",
      "Epoch 0.500000, Training: loss=0.191085, acc=0.943417.\t\tTesting: loss=0.189160, acc=0.940500\n",
      "Epoch 0.583333, Training: loss=0.124252, acc=0.962167.\t\tTesting: loss=0.129015, acc=0.959200\n",
      "Epoch 0.666667, Training: loss=0.149596, acc=0.954783.\t\tTesting: loss=0.151029, acc=0.953600\n",
      "Epoch 0.750000, Training: loss=0.104820, acc=0.968783.\t\tTesting: loss=0.103120, acc=0.967800\n",
      "Epoch 0.833333, Training: loss=0.093503, acc=0.970950.\t\tTesting: loss=0.095178, acc=0.969500\n",
      "Epoch 0.916667, Training: loss=0.099272, acc=0.969367.\t\tTesting: loss=0.112114, acc=0.965500\n",
      "Epoch 1, Training: loss=0.097577, acc=0.970250.\t\tTesting: loss=0.101059, acc=0.969300\n",
      "Cost 104.175459 seconds\n",
      "Optimization Finished!\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEWCAYAAABIVsEJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5c3f60ff50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loading training and testing data\n",
    "ims, labels, ims_mean = load_mnist_data('train', data_path='MNIST_data')\n",
    "#ims_mean = np.zeros((28*28))\n",
    "ims_test, labels_test, _ = load_mnist_data('test', data_path='MNIST_data')\n",
    "\n",
    "order_list = range(len(ims))\n",
    "\n",
    "# parameters related to mnist dataset \n",
    "test_iter = len(ims_test)/test_batch_size # number of testing-minibatch.\n",
    "\n",
    "iter_per_epoch = len(ims)/batch_size      # number of training-minibatch.\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Keep training until reach max iterations\n",
    "    x, y, cost, pred, one_hot_y = RNN()\n",
    "    train_loss = cost/batch_size # loss per image\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(train_loss)\n",
    "\n",
    "\n",
    "    # Evaluate model\n",
    "    correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(one_hot_y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "\n",
    "    # initialize all variables\n",
    "    try:\n",
    "        init = tf.initialize_all_variables()\n",
    "    except:\n",
    "        init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    Loss_plt = {'x':[], 'train_y':[], 'test_y':[]}\n",
    "    Acc_plt  = {'x':[], 'train_y':[], 'test_y':[]} \n",
    "    # Before Training (Random initialization), Evaluate the model one-time.\n",
    "    begin = time.time()\n",
    "    Train_Loss, Train_Acc, Test_Loss, Test_Acc=eval_model(sess, x, y, ims, labels, ims_test, labels_test, ims_mean, iter_per_epoch, test_iter)\n",
    "    print \"------After Random Initialization------\"\n",
    "    print \"Training: loss=%f, acc=%f.\\t\\tTesting: loss=%f, acc=%f\" %(Train_Loss/iter_per_epoch, Train_Acc/iter_per_epoch,\n",
    "                                                                     Test_Loss/test_iter, Test_Acc/test_iter)\n",
    "    \n",
    "    epoch = 0\n",
    "    step = 0      \n",
    "    \n",
    "    Loss_plt['x'].append(float(step)/iter_per_epoch)\n",
    "    Loss_plt['train_y'].append(Train_Loss/iter_per_epoch)\n",
    "    Loss_plt['test_y'].append(Test_Loss/test_iter)\n",
    "    Acc_plt['x'].append(float(step)/iter_per_epoch)\n",
    "    Acc_plt['train_y'].append(Train_Acc/iter_per_epoch)\n",
    "    Acc_plt['test_y'].append(Test_Acc/test_iter)\n",
    "    \n",
    "    duration = time.time()-begin\n",
    "    print \" %f seconds\"%(duration)\n",
    "    \n",
    "    print \"------Start Training------\"\n",
    "\n",
    "    for epoch in xrange(training_epochs):\n",
    "        begin = time.time()\n",
    "        Train_Loss = 0\n",
    "        Test_Loss = 0\n",
    "        Train_Acc = 0\n",
    "        Test_Acc = 0\n",
    "        for idx in xrange(iter_per_epoch):\n",
    "            batch_xs = ims[order_list[idx*batch_size:(idx+1)*batch_size]] - ims_mean\n",
    "            batch_ys = labels[order_list[idx*batch_size:(idx+1)*batch_size]]\n",
    "            # Run optimization op (backprop)\n",
    "            sess.run([optimizer], feed_dict={x: batch_xs, y: batch_ys})\n",
    "            if step % display_step == 0:\n",
    "                Train_Loss, Train_Acc, Test_Loss, Test_Acc=eval_model(sess, x, y, ims, labels, ims_test, labels_test, ims_mean, iter_per_epoch, test_iter)\n",
    "                print \"Epoch %f, Training: loss=%f, acc=%f.\\t\\tTesting: loss=%f, acc=%f\"%(float(step)/iter_per_epoch, Train_Loss/iter_per_epoch, Train_Acc/iter_per_epoch, \n",
    "                                                                                         Test_Loss/test_iter, Test_Acc/test_iter)\n",
    "                Loss_plt['x'].append(float(step)/iter_per_epoch)\n",
    "                Loss_plt['train_y'].append(Train_Loss/iter_per_epoch)\n",
    "                Loss_plt['test_y'].append(Test_Loss/test_iter)\n",
    "                Acc_plt['x'].append(float(step)/iter_per_epoch)\n",
    "                Acc_plt['train_y'].append(Train_Acc/iter_per_epoch)\n",
    "                Acc_plt['test_y'].append(Test_Acc/test_iter)\n",
    "            step += 1\n",
    "        \n",
    "        # Evaluate after each epoch finished.\n",
    "        Train_Loss, Train_Acc, Test_Loss, Test_Acc=eval_model(sess, x, y, ims, labels, ims_test, labels_test, ims_mean, iter_per_epoch, test_iter)\n",
    "        print \"Epoch %d, Training: loss=%f, acc=%f.\\t\\tTesting: loss=%f, acc=%f\"%(epoch+1, Train_Loss/iter_per_epoch, Train_Acc/iter_per_epoch, \n",
    "                                                                                         Test_Loss/test_iter, Test_Acc/test_iter)\n",
    "        Loss_plt['x'].append(float(step)/iter_per_epoch)\n",
    "        Loss_plt['train_y'].append(Train_Loss/iter_per_epoch)\n",
    "        Loss_plt['test_y'].append(Test_Loss/test_iter)\n",
    "        Acc_plt['x'].append(float(step)/iter_per_epoch)\n",
    "        Acc_plt['train_y'].append(Train_Acc/iter_per_epoch)\n",
    "        Acc_plt['test_y'].append(Test_Acc/test_iter)\n",
    "        duration = time.time()-begin\n",
    "        print \"Cost %f seconds\"%(duration)\n",
    "    print(\"Optimization Finished!\")\n",
    "    plt.figure(1)\n",
    "    plt.subplot(211)\n",
    "    plt.title('Loss. Blue-training, Red-testing')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.axis([0, training_epochs, 0, 5.0])\n",
    "    plt.plot(Loss_plt['x'], Loss_plt['train_y'], 'b-',Loss_plt['x'], Loss_plt['test_y'], 'r-')\n",
    "    plt.subplot(212)\n",
    "    plt.title('Accuracy. Blue-training, Red-testing')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('(%)')\n",
    "    plt.axis([0, training_epochs, 0, 1.0])\n",
    "    plt.plot(Acc_plt['x'], Acc_plt['train_y'], 'b-', Acc_plt['x'], Acc_plt['test_y'], 'r-')\n",
    "    plt.show()\n",
    " "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Possible Results\n",
    "------After Random Initialization------\n",
    "Training: loss=2.853943, acc=0.085467.\t\tTesting: loss=2.856901, acc=0.090800\n",
    " 8.238626 seconds\n",
    "------Start Training------\n",
    "Epoch 0.000000, Training: loss=2.386962, acc=0.267517.\t\tTesting: loss=2.363946, acc=0.267900\n",
    "Epoch 0.083333, Training: loss=0.475765, acc=0.853267.\t\tTesting: loss=0.464164, acc=0.860400\n",
    "Epoch 0.166667, Training: loss=0.344172, acc=0.894317.\t\tTesting: loss=0.349722, acc=0.893500\n",
    "Epoch 0.250000, Training: loss=0.251788, acc=0.922267.\t\tTesting: loss=0.239763, acc=0.924100\n",
    "Epoch 0.333333, Training: loss=0.185987, acc=0.942233.\t\tTesting: loss=0.187578, acc=0.941400\n",
    "Epoch 0.416667, Training: loss=0.142461, acc=0.955950.\t\tTesting: loss=0.142172, acc=0.956500\n",
    "Epoch 0.500000, Training: loss=0.135455, acc=0.958617.\t\tTesting: loss=0.137519, acc=0.956900\n",
    "Epoch 0.583333, Training: loss=0.118036, acc=0.964783.\t\tTesting: loss=0.125609, acc=0.960200\n",
    "Epoch 0.666667, Training: loss=0.135859, acc=0.961700.\t\tTesting: loss=0.146974, acc=0.956000\n",
    "Epoch 0.750000, Training: loss=0.112599, acc=0.966583.\t\tTesting: loss=0.119863, acc=0.963200\n",
    "Epoch 0.833333, Training: loss=0.127726, acc=0.960500.\t\tTesting: loss=0.133251, acc=0.959300\n",
    "Epoch 0.916667, Training: loss=0.098880, acc=0.969883.\t\tTesting: loss=0.105006, acc=0.968000\n",
    "Epoch 1, Training: loss=0.099234, acc=0.969933.\t\tTesting: loss=0.111800, acc=0.966600\n",
    "Cost 126.912962 seconds\n",
    "Optimization Finished!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
