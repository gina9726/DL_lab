{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "$\n",
    "\\begin{equation}\n",
    "y = W \\cdot x + b\n",
    "\\end{equation}\n",
    "$\n",
    "\n",
    "Given some data points and their labels, we can learn the parameters (W and b) of the model by reducing the loss.\n",
    "\n",
    "The answer of this model's parameters are:  \n",
    "W_ans = [[3, 5]]  \n",
    "b_ans = [7] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data & label\n",
    "data = np.array([[2, 6], [1, 2], [4, 5], [6, 8]])\n",
    "label = np.array([[43], [20], [44], [65]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the graph (define your model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[batch_size, data_dim] = data.shape\n",
    "# reserve place for x and y by placeholder\n",
    "x = tf.placeholder(tf.float32, [batch_size, data_dim])\n",
    "y = tf.placeholder(tf.float32, [batch_size, 1])\n",
    "\n",
    "# W and b are random initialized\n",
    "W = tf.Variable(tf.random_uniform([data_dim, 1], -1, 1))\n",
    "b = tf.Variable(tf.random_uniform([1], -1, 1))\n",
    "\n",
    "# y = w*x+b\n",
    "y_pred = tf.add(tf.matmul(x, W), b)\n",
    "\n",
    "# compute the loss\n",
    "loss = tf.reduce_mean(tf.square(y-y_pred))\n",
    "\n",
    "# declare an optimizer\n",
    "opt = tf.train.AdamOptimizer(learning_rate=1).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/planck/anaconda2/lib/python2.7/site-packages/tensorflow/python/util/tf_should_use.py:170: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "# create a session\n",
    "sess = tf.Session()\n",
    "# initialize variables\n",
    "sess.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_params(sess):\n",
    "    param_w, param_b  = sess.run([W, b])\n",
    "    print('W =')\n",
    "    print(param_w)\n",
    "    print('b =')\n",
    "    print(param_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training, loss = 2050.5234375\n",
      "Prediction:\n",
      "[[ 0.10971522]\n",
      " [ 0.31419683]\n",
      " [ 0.75460267]\n",
      " [ 0.93111205]]\n",
      "W =\n",
      "[[ 0.26389647]\n",
      " [-0.11709452]]\n",
      "b =\n",
      "[ 0.28448939]\n",
      "Training ...\n",
      "Iter: 20 loss: 56.2125587463\n",
      "Iter: 40 loss: 2.9620950222\n",
      "Iter: 60 loss: 1.32308363914\n",
      "Iter: 80 loss: 0.156150564551\n",
      "Iter: 100 loss: 0.0206669103354\n",
      "Iter: 120 loss: 0.00856634601951\n",
      "Iter: 140 loss: 0.00138573534787\n",
      "Iter: 160 loss: 0.000718749128282\n",
      "Iter: 180 loss: 0.000287723902147\n",
      "Iter: 200 loss: 0.000123188743601\n",
      "Training is done.\n",
      "Prediction:\n",
      "[[ 42.98777771]\n",
      " [ 20.01573563]\n",
      " [ 44.00854111]\n",
      " [ 64.995224  ]]\n",
      "W =\n",
      "[[ 3.00605559]\n",
      " [ 4.99170017]]\n",
      "b =\n",
      "[ 7.02607918]\n"
     ]
    }
   ],
   "source": [
    "# feed the data, and run the session\n",
    "# let's evaluate before training\n",
    "pred, loss_val = sess.run([y_pred, loss], feed_dict={x: data, y: label})                                                                                                                                     \n",
    "print('Before training, loss = {}'.format(loss_val))\n",
    "print('Prediction:')\n",
    "print(pred)\n",
    "print_params(sess)\n",
    "\n",
    "# training parameters (W & b)\n",
    "max_iter = 200\n",
    "show_iter = 20\n",
    "print('Training ...')\n",
    "for i in range(1, max_iter+1):\n",
    "    pred, loss_val, _ = sess.run([y_pred, loss, opt], feed_dict={x: data, y: label})\n",
    "    \n",
    "    if i%show_iter == 0:\n",
    "        print('Iter: {} loss: {}'.format(i, loss_val))\n",
    "\n",
    "print('Training is done.')\n",
    "print('Prediction:')\n",
    "print(pred)\n",
    "print_params(sess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
